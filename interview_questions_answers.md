# 공공도서관 리뷰 감성분석 프로젝트 - 면접 질문 & 모범답안

---

## 목차
1. [프로젝트 개요](#1-프로젝트-개요)
2. [데이터 수집](#2-데이터-수집)
3. [데이터 전처리](#3-데이터-전처리)
4. [자연어 처리(NLP)](#4-자연어-처리nlp)
5. [감성분석](#5-감성분석)
6. [데이터 분석 및 통계](#6-데이터-분석-및-통계)
7. [시각화](#7-시각화)
8. [코드 설계 및 아키텍처](#8-코드-설계-및-아키텍처)
9. [한계점 및 개선방안](#9-한계점-및-개선방안)
10. [심화 질문](#10-심화-질문)

---

## 1. 프로젝트 개요

### Q1. 이 프로젝트의 목적과 전체적인 흐름을 설명해주세요.

**모범답안:**

이 프로젝트는 전국 공공도서관에 대한 네이버 블로그 리뷰를 수집하고, 감성분석을 수행하여 도서관 서비스 품질을 정량적으로 평가하는 것을 목적으로 합니다.

전체 흐름은 다음과 같습니다:

1. **데이터 수집 단계:** 전국도서관표준데이터(CSV)에서 도서관 기본 정보를 확보하고, 네이버 블로그 검색 API를 활용하여 각 도서관에 대한 블로그 리뷰 17,526건을 수집했습니다.
2. **데이터 전처리 단계:** 도서관 정보의 결측치 처리, 이상치 제거(99백분위수 캡핑), 주소에서 시도/시군구 정보를 추출하고, 리뷰 텍스트에서 HTML 태그 제거 및 엔티티 디코딩을 수행했습니다.
3. **감성분석 단계:** 긍정/부정/중립 키워드 사전을 구축하고, 강조 표현 가중치(1.5배)와 부정어 처리를 적용한 규칙 기반 감성 점수를 산출했습니다.
4. **분석 및 시각화 단계:** 지역별, 도서관 유형별, 시군구별 감성 비교 분석, 도서관 시설 특성과 감성 점수의 상관관계 분석, 시계열 트렌드 분석, 워드클라우드 생성 등을 수행했습니다.

최종적으로 도서관 운영 개선을 위한 데이터 기반 인사이트를 도출하는 것이 프로젝트의 핵심 가치입니다.

---

### Q2. 이 프로젝트에서 본인의 역할과 기여한 부분은 무엇인가요?

**모범답안:**

저는 이 프로젝트의 전 과정을 담당했습니다. 구체적으로는:

- **데이터 파이프라인 설계:** 원천 데이터 수집부터 최종 분석까지의 전체 워크플로우를 설계했습니다.
- **API 크롤러 개발:** 네이버 블로그 검색 API를 활용한 데이터 수집 모듈을 개발했으며, Rate Limiting, 에러 핸들링, 중간 저장 기능을 구현했습니다.
- **전처리 파이프라인 구축:** 3,518개 도서관 데이터의 정제와 17,526건 리뷰의 텍스트 전처리를 수행했습니다.
- **감성분석 엔진 개발:** 한국어 특화 감성 키워드 사전(긍정 48개, 부정 56개, 중립 8개)을 구축하고, 강조 표현과 부정어를 고려한 점수 산출 알고리즘을 설계했습니다.
- **분석 및 시각화:** 상관관계 분석, 지역별/유형별 비교 분석, 시계열 분석, 워드클라우드 등 다양한 분석과 시각화를 수행했습니다.

---

### Q3. 왜 공공도서관을 분석 대상으로 선택했나요?

**모범답안:**

공공도서관은 전국에 약 3,500개 이상 운영되는 대표적인 공공 서비스 시설이며, 이에 대한 체계적인 이용자 만족도 분석이 부족한 상황이었습니다. 기존에는 설문조사 기반의 만족도 조사가 주로 이루어졌는데, 이는 표본 수가 제한적이고 응답 편향이 존재합니다.

반면 블로그 리뷰는 이용자가 자발적으로 작성한 비정형 텍스트 데이터로, 솔직한 의견이 반영되어 있습니다. 네이버 블로그는 한국에서 가장 활발한 리뷰 플랫폼 중 하나이므로 충분한 데이터를 확보할 수 있었습니다.

이를 통해 도서관 운영 개선에 실질적으로 활용 가능한 데이터 기반 인사이트를 제공하고자 했습니다.

---

## 2. 데이터 수집

### Q4. 네이버 블로그 API를 활용한 데이터 수집 과정을 설명해주세요.

**모범답안:**

네이버 블로그 검색 API(v1)를 활용하여 데이터를 수집했습니다.

1. **API 설정:** 네이버 개발자 센터에서 Client ID와 Client Secret을 발급받고, `NaverBlogSearchAPI` 클래스를 구현했습니다.
2. **검색 전략:** 각 도서관 이름을 검색 쿼리로 사용하여, 도서관당 최대 5건의 블로그 게시글을 수집했습니다. `urllib.parse.quote`를 사용해 한글 쿼리를 URL 인코딩했습니다.
3. **페이지네이션:** `display`(결과 개수)와 `start`(시작 위치) 파라미터를 조절하여 페이지네이션을 구현했습니다.
4. **Rate Limiting:** API 호출 간 1초의 딜레이를 두어 서버 부하를 방지했습니다.
5. **에러 핸들링:** API 응답 오류 시 재시도 로직을 구현하고, 에러 발생 시에도 프로그램이 중단되지 않도록 예외 처리를 적용했습니다.
6. **데이터 정제:** 응답에서 HTML 태그(`<b>`, `</b>` 등)를 제거하고, HTML 엔티티(`&quot;`, `&amp;` 등)를 디코딩했습니다.
7. **중간 저장:** 수집 중 CSV 파일에 점진적으로 저장하여, 중단 시에도 이미 수집된 데이터가 유실되지 않도록 했습니다.

최종적으로 3,518개 도서관에 대해 총 17,526건의 블로그 리뷰를 수집했습니다.

---

### Q5. 크롤링 과정에서 발생할 수 있는 문제점과 해결 방법은?

**모범답안:**

주요 문제점과 해결 방법은 다음과 같습니다:

1. **API Rate Limit 초과:**
   - 문제: 너무 빠른 요청 시 429 에러 발생
   - 해결: 라이브러리 간 1초 딜레이 적용, 에러 발생 시 지수 백오프(exponential backoff) 적용

2. **네트워크 오류:**
   - 문제: 타임아웃, 연결 끊김 등
   - 해결: try-except로 예외 처리, 재시도 로직 구현, 중간 결과 저장으로 데이터 유실 방지

3. **검색 결과의 관련성:**
   - 문제: 도서관 이름 검색 시 무관한 결과가 포함될 수 있음
   - 해결: 블로그 제목과 내용에 도서관 이름이 포함된 결과를 우선적으로 수집

4. **HTML 태그 및 특수문자:**
   - 문제: API 응답에 HTML 태그와 엔티티가 포함
   - 해결: 정규표현식으로 HTML 태그 제거, `html.unescape` 또는 수동 매핑으로 엔티티 디코딩

5. **API 키 보안:**
   - 문제: 소스 코드에 API 키가 하드코딩됨
   - 개선 방안: 환경 변수나 `.env` 파일을 통한 키 관리로 전환 필요

---

### Q6. API 대신 웹 스크래핑(크롤링)을 사용했다면 어떤 차이가 있었을까요?

**모범답안:**

API와 웹 스크래핑의 차이는 다음과 같습니다:

| 구분 | API | 웹 스크래핑 |
|------|-----|------------|
| 안정성 | 높음 (구조화된 JSON 응답) | 낮음 (HTML 구조 변경 시 코드 수정 필요) |
| 속도 | 빠름 | 상대적으로 느림 (페이지 렌더링 필요) |
| 법적 리스크 | 낮음 (공식 제공) | robots.txt 및 이용약관 위반 가능성 |
| 데이터 범위 | API가 제공하는 범위로 제한 | 화면에 보이는 모든 데이터 접근 가능 |
| 유지보수 | 낮음 (API 버전 관리) | 높음 (웹사이트 구조 변경에 취약) |

이 프로젝트에서는 네이버 공식 API를 사용하여 법적으로 안전하면서도 구조화된 데이터를 효율적으로 수집할 수 있었습니다. 다만 API의 한계(최대 1,000건 제한)로 인해 대량 수집에는 제약이 있었습니다.

---

## 3. 데이터 전처리

### Q7. 데이터 전처리 과정에서 어떤 작업들을 수행했나요?

**모범답안:**

데이터 전처리는 도서관 정보와 리뷰 텍스트 두 가지 축으로 수행했습니다.

**도서관 정보 전처리:**
1. **중복 제거:** 동일한 도서관이 중복 등록된 경우 제거
2. **결측치 처리:** 수치형 컬럼의 결측치를 NaN으로 변환
3. **이상치 처리:** 99백분위수(percentile) 기반 캡핑으로 극단값 제거. 음수값은 NaN으로 변환
4. **주소 파싱:** 도로명주소와 지번주소에서 정규표현식을 활용하여 시도명(16개 광역시/도)과 시군구명을 추출
5. **데이터 타입 변환:** 건물면적, 좌석수, 대출가능권수 등을 수치형으로 변환
6. **텍스트 정규화:** 도서관명 앞뒤 공백 제거

**리뷰 텍스트 전처리:**
1. **HTML 태그 제거:** `re.sub(r'<[^>]+>', '', text)`로 모든 HTML 태그 제거
2. **HTML 엔티티 디코딩:** `&quot;`, `&amp;`, `&lt;`, `&gt;`, `&nbsp;`, `&apos;` 등을 원래 문자로 변환
3. **공백 정규화:** 연속된 공백을 하나로 축소, 앞뒤 공백 제거
4. **텍스트 길이 계산:** 분석용 메타데이터로 텍스트 길이 컬럼 추가

---

### Q8. 이상치(Outlier)를 어떻게 처리했고, 왜 그 방법을 선택했나요?

**모범답안:**

이상치 처리는 99백분위수 캡핑(Capping/Winsorizing) 방법을 사용했습니다.

```python
upper_limit = df[col].quantile(0.99)
df[col] = df[col].clip(upper=upper_limit)
```

이 방법을 선택한 이유는 다음과 같습니다:

1. **데이터 보존:** IQR 방식이나 Z-score 방식으로 이상치를 삭제하면 해당 도서관의 전체 레코드가 소실됩니다. 캡핑은 극단값만 상한선으로 대체하므로 데이터 손실이 없습니다.
2. **도메인 특성:** 도서관의 건물면적이나 좌석수는 실제로 매우 큰 시설이 존재할 수 있어, 단순 삭제보다는 상한 조정이 더 적절합니다.
3. **분석 안정성:** 상관관계 분석이나 평균 계산에서 극단값의 영향을 줄이면서도 데이터의 전체 분포를 유지할 수 있습니다.

추가로 음수값에 대해서는 물리적으로 불가능한 값(좌석수 음수 등)이므로 NaN으로 변환하여 처리했습니다.

---

### Q9. 결측치 처리 방법으로 무엇을 사용했고, 다른 방법과 비교하면?

**모범답안:**

이 프로젝트에서는 결측치를 **NaN으로 유지**하는 방식을 채택했습니다. pandas의 대부분의 통계 함수가 NaN을 자동으로 제외하고 계산하기 때문입니다.

대안적인 방법과 비교하면:

| 방법 | 장점 | 단점 | 적합한 경우 |
|------|------|------|------------|
| NaN 유지 (본 프로젝트) | 데이터 왜곡 없음 | 분석 시 데이터 수 감소 | 결측 비율이 낮을 때 |
| 평균/중앙값 대체 | 데이터 수 유지 | 분산 축소, 분포 왜곡 | 결측이 랜덤할 때 |
| 최빈값 대체 | 범주형에 적합 | 편향 발생 가능 | 범주형 데이터 |
| 보간법(Interpolation) | 연속적 패턴 유지 | 계산 복잡 | 시계열 데이터 |
| 삭제(Listwise) | 완전한 데이터만 사용 | 데이터 대량 손실 가능 | 결측이 매우 적을 때 |

NaN 유지를 선택한 이유는, 도서관 데이터에서 건물면적이나 좌석수의 결측은 "정보 미제공"을 의미하므로, 임의의 값으로 대체하면 오히려 분석 결과를 왜곡할 수 있기 때문입니다.

---

## 4. 자연어 처리(NLP)

### Q10. KoNLPy와 Okt를 선택한 이유는 무엇인가요?

**모범답안:**

KoNLPy는 한국어 자연어 처리를 위한 대표적인 파이썬 라이브러리이고, 그 중 Okt(Open Korean Text)를 선택한 이유는 다음과 같습니다:

1. **속도:** Okt는 KoNLPy에서 제공하는 형태소 분석기(Kkma, Komoran, Hannanum, Mecab, Okt) 중 비교적 빠른 처리 속도를 보여줍니다. 17,526건의 리뷰를 처리해야 하므로 속도가 중요했습니다.
2. **정규화 기능:** Okt는 `normalize()` 기능을 내장하고 있어 "그래욬ㅋㅋ" → "그래요"와 같은 구어체 정규화가 가능합니다. 블로그 리뷰는 구어체가 많아 이 기능이 유용합니다.
3. **명사 추출:** `nouns()` 메서드로 명사만 간편하게 추출할 수 있어 키워드 분석에 적합합니다.
4. **설치 용이성:** Mecab은 성능이 우수하지만 별도 사전 설치가 필요합니다. Okt는 KoNLPy 설치만으로 바로 사용 가능합니다.

다만 Mecab이 형태소 분석 정확도와 속도 모두에서 더 우수하므로, 프로덕션 환경에서는 Mecab으로의 전환을 고려할 수 있습니다.

---

### Q11. 불용어(Stopwords) 처리는 어떻게 했나요?

**모범답안:**

불용어 처리는 도메인 특화 방식으로 수행했습니다.

1. **도메인 불용어:** 도서관 관련 일반 단어 200개 이상을 직접 정의했습니다. 예: "도서관", "책", "열람", "대출", "자료", "이용", "시간" 등. 이 단어들은 거의 모든 리뷰에 등장하므로 키워드 분석에서 변별력이 없습니다.

2. **지역명 불용어:** "서울", "부산", "대구" 등 지역명을 불용어로 처리했습니다. 지역별 분석 시 해당 지역명이 당연히 빈출하므로 제외해야 의미 있는 키워드를 추출할 수 있습니다.

3. **필터링 조건:**
   - 최소 단어 길이: 2글자 이상 (한 글자 명사는 의미가 모호)
   - 최소 출현 빈도: 3회 이상 (너무 희귀한 단어는 대표성 부족)
   - 순수 숫자 제외: 연도나 전화번호 등 무의미한 숫자 제거

이러한 불용어 처리를 통해 "분위기", "프로그램", "아이", "공간" 등 실제로 도서관 이용 경험을 반영하는 핵심 키워드를 효과적으로 추출할 수 있었습니다.

---

### Q12. 형태소 분석이란 무엇이고, 왜 한국어에서 특히 중요한가요?

**모범답안:**

형태소 분석은 텍스트를 의미를 가진 최소 단위인 형태소(morpheme)로 분리하는 과정입니다.

한국어에서 특히 중요한 이유는:

1. **교착어 특성:** 한국어는 어근에 조사, 어미가 결합하는 교착어입니다. "도서관에서", "도서관을", "도서관이" 모두 "도서관"이라는 동일한 의미를 가지지만, 단순 공백 기반 토큰화로는 다른 단어로 처리됩니다.

2. **띄어쓰기 비일관성:** 한국어는 영어와 달리 띄어쓰기 규칙이 복잡하고, 실제 텍스트에서 띄어쓰기 오류가 빈번합니다. 형태소 분석기는 이를 보정할 수 있습니다.

3. **어순 자유도:** 한국어는 어순이 비교적 자유로워 문맥 파악에 형태소 단위 분석이 필요합니다.

이 프로젝트에서는 Okt의 `nouns()` 메서드를 사용하여 명사만 추출했는데, 이는 키워드 분석과 워드클라우드 생성에 가장 적합한 접근법입니다. 명사는 주제와 대상을 가장 직접적으로 나타내는 품사이기 때문입니다.

---

## 5. 감성분석

### Q13. 감성분석 알고리즘의 작동 원리를 설명해주세요.

**모범답안:**

이 프로젝트에서는 **규칙 기반(Rule-based) 감성분석**을 사용했습니다. 작동 원리는 다음과 같습니다:

1. **감성 사전 구축:**
   - 긍정 키워드 48개: "좋은", "만족", "친절", "깨끗", "추천", "편리", "쾌적" 등
   - 부정 키워드 56개: "불편", "부족", "좁은", "오래된", "낡은", "불친절", "실망" 등
   - 중립 키워드 8개: "보통", "평범", "그럭저럭", "무난" 등

2. **키워드 매칭:** 리뷰 텍스트에서 각 키워드의 출현 횟수를 카운트합니다.

3. **가중치 적용:**
   - 강조 표현 감지: "매우", "정말", "너무" 등이 키워드 앞에 오면 1.5배 가중치 적용
   - 부정어 처리: "안", "못", "없", "아니" 등이 키워드 앞에 오면 감성 극성을 반전

4. **점수 산출:**
   ```
   감성 점수 = (긍정 키워드 가중 합계) - (부정 키워드 가중 합계)
   ```

5. **라벨 할당:**
   - 점수 > 2: 긍정(positive)
   - 점수 < -2: 부정(negative)
   - 그 외: 중립(neutral)

임계값을 ±2로 설정한 이유는, 블로그 리뷰 특성상 긍정/부정 표현이 혼재하는 경우가 많아 일정 수준 이상의 명확한 감성 경향이 있을 때만 분류하기 위함입니다.

---

### Q14. 규칙 기반 감성분석의 장단점과 머신러닝 기반 대비 차이점은?

**모범답안:**

**규칙 기반 감성분석의 장점:**
- 해석 가능성이 높음: 왜 긍정/부정으로 판단했는지 키워드 단위로 설명 가능
- 라벨링된 학습 데이터 불필요: 감성 사전만 있으면 바로 적용 가능
- 도메인 특화 용이: 도서관 관련 감성 표현을 직접 정의 가능
- 빠른 구현과 실행 속도

**규칙 기반 감성분석의 단점:**
- 문맥 이해 부족: "좋다고 하기 어렵다"와 같은 복합 표현 처리 어려움
- 키워드 사전 의존: 사전에 없는 새로운 표현 감지 불가
- 비꼬기/반어법 처리 불가: "정말 대단하시네요(비꼼)" 같은 표현
- 확장성 제한: 새로운 도메인 적용 시 사전을 처음부터 다시 구축 필요

**머신러닝 기반과의 비교:**

| 구분 | 규칙 기반 | 머신러닝 기반 |
|------|----------|-------------|
| 학습 데이터 | 불필요 | 대량 라벨링 데이터 필요 |
| 문맥 이해 | 제한적 | 우수 (특히 딥러닝) |
| 해석 가능성 | 높음 | 낮음 (블랙박스) |
| 정확도 | 중간 | 높음 |
| 개발 비용 | 낮음 | 높음 |
| 유지보수 | 사전 업데이트 | 모델 재학습 |

이 프로젝트에서 규칙 기반을 선택한 이유는, 라벨링된 도서관 리뷰 학습 데이터가 없었고, 분석 결과의 해석 가능성이 중요했기 때문입니다.

---

### Q15. 감성분석의 정확도를 어떻게 검증했나요? 또는 검증하려면 어떻게 해야 하나요?

**모범답안:**

현재 프로젝트에서는 정량적 정확도 검증이 수행되지 않았으며, 이는 개선이 필요한 부분입니다. 검증 방법으로는 다음을 고려할 수 있습니다:

1. **수동 라벨링 검증:**
   - 랜덤 샘플 300~500건에 대해 사람이 직접 긍정/부정/중립 라벨을 부여
   - 모델 예측과 비교하여 정확도(Accuracy), 정밀도(Precision), 재현율(Recall), F1-Score 계산
   - Cohen's Kappa로 평가자 간 일치도도 함께 측정

2. **교차 검증:**
   - 다른 감성분석 도구(KoBERT, VADER 한국어 버전 등)와 결과를 비교
   - 일치율을 통해 신뢰성 간접 확인

3. **혼동 행렬(Confusion Matrix) 분석:**
   - 오분류 패턴을 파악하여 감성 사전 보완
   - 예: 긍정을 중립으로 분류하는 경우가 많다면 긍정 키워드 보강

4. **A/B 테스트:**
   - 규칙 기반 vs 머신러닝 기반 결과를 비교하여 실용성 평가

향후 개선 시, 수동 라벨링 데이터를 확보한 후 KoBERT 같은 사전학습 모델로 전환하면 정확도를 크게 향상시킬 수 있습니다.

---

### Q16. 부정어와 강조 표현을 어떻게 처리했나요?

**모범답안:**

**강조 표현 처리:**
- "매우", "정말", "너무", "아주", "엄청" 등의 강조 부사가 감성 키워드 앞에 위치하면 해당 키워드의 가중치를 1.5배로 적용했습니다.
- 예: "정말 깨끗한" → 긍정 점수 1.0이 아닌 1.5로 계산

**부정어 처리:**
- "안", "못", "없", "아니" 등의 부정 표현이 감성 키워드 앞에 위치하면 감성 극성을 반전시켰습니다.
- 예: "안 좋은" → 긍정이 아닌 부정으로 처리

**한계점:**
- 단순 위치 기반 판단이라 "안 좋은 것은 아니다"와 같은 이중 부정 처리가 어렵습니다.
- 키워드 간 거리를 고려하지 않아, 문장 내 멀리 떨어진 부정어가 잘못 매칭될 수 있습니다.
- 향후 의존 구문 분석(dependency parsing)을 적용하면 더 정확한 부정어-키워드 관계를 파악할 수 있습니다.

---

## 6. 데이터 분석 및 통계

### Q17. 도서관 시설 특성과 감성 점수 간 상관관계 분석 결과를 설명해주세요.

**모범답안:**

도서관의 6가지 시설 특성과 감성 점수 간의 상관관계를 분석했습니다:

**분석 변수:**
- 열람좌석수, 자료수(도서), 건물면적, 평일운영시간, 대출가능권수, 대출가능일수

**분석 방법:**
1. 독립 변수에 대해 Min-Max Scaling(0~1 정규화)을 적용하여 변수 간 스케일 차이를 제거했습니다.
2. 산점도와 다항 회귀선(polynomial fit)을 통해 시각적 패턴을 확인했습니다.
3. 피어슨 상관계수를 계산하여 선형 관계의 강도를 측정했습니다.

**인사이트 도출:**
- 상관관계 분석을 통해 어떤 시설 특성이 이용자 만족도와 가장 관련이 있는지 파악할 수 있습니다.
- 산점도의 점 크기를 리뷰 수로 설정하여, 데이터 신뢰도도 함께 시각화했습니다.
- 상관관계가 인과관계를 의미하지는 않으므로, 해석 시 주의가 필요합니다.

---

### Q18. Min-Max Scaling을 왜 사용했고, 다른 스케일링 방법과 비교하면?

**모범답안:**

Min-Max Scaling은 데이터를 0~1 범위로 정규화하는 방법입니다:

```
X_scaled = (X - X_min) / (X_max - X_min)
```

**사용 이유:**
- 건물면적(수천 m²)과 대출가능권수(5~10권) 등 스케일이 크게 다른 변수들을 동일 범위로 변환하여 공정한 비교가 가능합니다.
- 상관관계 시각화에서 직관적인 해석이 가능합니다.

**다른 스케일링 방법 비교:**

| 방법 | 수식 | 특징 | 적합한 경우 |
|------|------|------|------------|
| Min-Max | (X-min)/(max-min) | 0~1 범위 고정 | 이상치 적을 때, 시각화 |
| Standard (Z-score) | (X-μ)/σ | 평균 0, 표준편차 1 | 정규분포 가정할 때 |
| Robust | (X-Q2)/(Q3-Q1) | 중앙값·IQR 기반 | 이상치 많을 때 |
| Log 변환 | log(X) | 왜도 감소 | 오른쪽 꼬리 분포 |

이 프로젝트에서는 이미 이상치를 99백분위수로 캡핑한 후 스케일링을 적용했으므로 Min-Max 방식이 적절했습니다. 이상치 처리를 하지 않았다면 Robust Scaling이 더 적합했을 것입니다.

---

### Q19. 시계열 분석에서 어떤 트렌드를 확인했나요?

**모범답안:**

시계열 분석에서는 두 가지 축으로 트렌드를 분석했습니다:

1. **연도별 감성 추이:**
   - 연도별 평균 감성 점수의 변화를 추적하여 도서관 서비스에 대한 인식 변화를 파악했습니다.
   - 리뷰 작성일(YYYYMMDD 형식)에서 연도를 추출하여 집계했습니다.

2. **월별 패턴:**
   - 계절적 패턴(방학 시기, 시험 기간 등)에 따른 감성 변화를 확인했습니다.
   - 이중 축 그래프를 사용하여 감성 점수와 리뷰 건수를 동시에 시각화했습니다.

**시계열 분석의 의의:**
- 특정 시기에 부정적 리뷰가 급증했다면, 해당 시기의 이벤트나 정책 변화를 추적할 수 있습니다.
- 리뷰 건수의 증감 추이를 통해 도서관에 대한 관심도 변화도 파악 가능합니다.
- 계절성 패턴은 도서관 운영 계획 수립에 활용될 수 있습니다.

---

## 7. 시각화

### Q20. 워드클라우드를 생성할 때 고려한 사항은 무엇인가요?

**모범답안:**

워드클라우드 생성 시 다음 사항을 고려했습니다:

1. **한글 폰트 설정:** Google Colab 환경에서 NanumGothic 폰트를 설치하여 한글이 깨지지 않도록 했습니다. 한글 폰트를 지정하지 않으면 글자가 네모(□)로 표시됩니다.

2. **불용어 제거:** 분석 목적에 맞지 않는 일반적인 단어(도서관, 책 등)를 제거하여 실질적인 키워드만 표시했습니다.

3. **시각적 설정:**
   - 해상도: 1200×600 픽셀로 충분한 가독성 확보
   - 최대 단어 수: 100개로 제한하여 가독성 유지
   - 컬러맵: viridis를 사용하여 시각적 구분 향상
   - 외곽선(contour): 스타일링 적용으로 시각적 완성도 제고
   - 배경색: 흰색으로 설정하여 인쇄 및 발표에 적합

4. **빈도 기반 크기 조절:** `collections.Counter`로 계산한 단어 빈도에 따라 글자 크기가 자동 결정되어, 자주 등장하는 키워드가 시각적으로 강조됩니다.

---

### Q21. 이 프로젝트에서 사용한 시각화 유형들과 각각의 목적을 설명해주세요.

**모범답안:**

| 시각화 유형 | 사용 목적 | 활용 장면 |
|------------|----------|----------|
| **워드클라우드** | 핵심 키워드의 빈도를 직관적으로 표현 | 지역별 주요 키워드 비교 |
| **박스 플롯** | 감성 점수의 분포와 이상치 확인 | 도서관 유형별/시군구별 감성 비교 |
| **막대 그래프** | 카테고리별 수치 비교 | 상위/하위 도서관 랭킹 |
| **산점도** | 두 변수 간 관계 파악 | 시설 특성과 감성 점수 상관관계 |
| **시계열 차트** | 시간에 따른 변화 추이 | 연도별/월별 감성 변화 |
| **이중 축 그래프** | 서로 다른 척도의 두 지표 동시 표현 | 감성 점수 + 리뷰 건수 동시 표시 |

시각화 라이브러리로는 matplotlib과 seaborn을 조합하여 사용했습니다. matplotlib은 세밀한 커스터마이징에, seaborn은 통계적 시각화에 각각 강점이 있어 목적에 맞게 활용했습니다.

---

## 8. 코드 설계 및 아키텍처

### Q22. LibraryAnalyzer 클래스의 설계 구조를 설명해주세요.

**모범답안:**

`LibraryAnalyzer` 클래스는 감성분석의 전체 파이프라인을 캡슐화한 핵심 클래스입니다.

**주요 구성요소:**

```
LibraryAnalyzer
├── __init__()                          # 데이터 로드, 감성 사전 초기화, 불용어 정의
├── preprocess_reviews()                # 리뷰 텍스트 전처리
├── preprocess_library_info()           # 도서관 정보 전처리
├── analyze_sentiment_advanced()        # 감성 점수 산출
├── extract_keywords()                  # KoNLPy 기반 키워드 추출
├── analyze_region_comprehensive()      # 지역별 종합 분석 (메인 메서드)
│   ├── _analyze_correlations()         # 시설-감성 상관관계
│   ├── _analyze_by_library_type()      # 도서관 유형별 분석
│   ├── _analyze_by_district()          # 시군구별 분석
│   └── _analyze_time_series()          # 시계열 분석
├── generate_enhanced_wordcloud()       # 워드클라우드 생성
└── generate_comprehensive_report()     # 다중 지역 종합 보고서
```

**설계 원칙:**
1. **단일 책임 원칙:** 각 메서드가 하나의 기능만 담당
2. **캡슐화:** 감성 사전, 불용어 등 내부 데이터를 클래스 내부에 관리
3. **재사용성:** `analyze_region_comprehensive()`에 지역명만 바꿔서 여러 지역 분석 가능
4. **확장성:** 새로운 분석 메서드를 쉽게 추가할 수 있는 구조

---

### Q23. 코드에서 개선할 수 있는 부분이 있다면?

**모범답안:**

여러 개선 포인트가 있습니다:

1. **API 키 보안:** 현재 소스 코드에 하드코딩되어 있는 API 키를 환경 변수나 `.env` 파일로 분리해야 합니다.
   ```python
   # 현재 (보안 취약)
   client_id = "MhwFqrTamD_qfZ24piL6"
   # 개선
   client_id = os.environ.get("NAVER_CLIENT_ID")
   ```

2. **설정 관리:** 임계값(±2), 가중치(1.5), 최소 리뷰 수(3) 등 매직 넘버를 설정 파일이나 상수로 분리해야 합니다.

3. **로깅:** `print` 대신 `logging` 모듈을 사용하여 레벨별 로그 관리가 필요합니다.

4. **테스트 코드:** 단위 테스트가 없어 리팩토링 시 안전성이 보장되지 않습니다. pytest 기반 테스트 추가가 필요합니다.

5. **타입 힌트:** 함수의 입출력 타입을 명시하여 가독성과 IDE 지원을 강화할 수 있습니다.

6. **모듈 분리:** 하나의 노트북에 모든 코드가 있어, 전처리/분석/시각화를 별도 모듈로 분리하면 유지보수성이 향상됩니다.

7. **감성분석 고도화:** 규칙 기반에서 KoBERT 등 사전학습 모델 기반으로 전환하면 정확도를 높일 수 있습니다.

---

## 9. 한계점 및 개선방안

### Q24. 이 프로젝트의 한계점과 개선 방안은 무엇인가요?

**모범답안:**

**한계점:**

1. **데이터 편향:**
   - 블로그 리뷰는 특정 연령대(20~40대)에 편중되어 전체 이용자를 대표하지 못합니다.
   - 긍정 편향: 블로그 특성상 긍정적 경험을 공유하는 경향이 강합니다.
   - 도서관당 최대 5건으로 표본이 제한적입니다.

2. **감성분석 한계:**
   - 규칙 기반으로 문맥과 맥락을 충분히 반영하지 못합니다.
   - 반어법, 비꼬기 등 복합적인 감성 표현 처리 어려움
   - 감성 사전의 완전성을 보장하기 어렵습니다.

3. **데이터 품질:**
   - 도서관 이름 검색 시 무관한 블로그 게시글이 포함될 수 있습니다.
   - 블로그 본문 전체가 아닌 요약(description)만 수집하여 정보 손실이 있습니다.

**개선 방안:**

1. **데이터 다양화:** 네이버 블로그 외에 카카오맵 리뷰, 구글 리뷰, SNS 데이터도 수집
2. **딥러닝 감성분석:** KoBERT, KoElectra 등 사전학습 모델 활용
3. **주제 모델링:** LDA, BERTopic 등을 활용한 토픽 모델링으로 리뷰 주제 자동 분류
4. **대시보드 구축:** Streamlit이나 Dash를 활용한 인터랙티브 대시보드 개발
5. **실시간 모니터링:** 주기적 크롤링과 자동 분석 파이프라인 구축

---

### Q25. 만약 이 프로젝트를 처음부터 다시 한다면, 어떤 점을 다르게 하겠습니까?

**모범답안:**

1. **데이터 수집 다각화:**
   - 네이버 블로그 외에 구글 리뷰, 카카오맵 리뷰, 트위터 등 다양한 데이터 소스를 확보하여 편향을 줄이겠습니다.
   - 블로그 본문 전체를 수집하여 더 풍부한 텍스트 분석이 가능하도록 하겠습니다.

2. **감성분석 모델:**
   - 초기에 소량의 데이터를 수동 라벨링하고, 이를 기반으로 KoBERT 파인튜닝을 수행하여 더 높은 정확도를 확보하겠습니다.
   - 규칙 기반과 ML 기반을 앙상블하는 하이브리드 접근법도 고려하겠습니다.

3. **코드 품질:**
   - 처음부터 모듈화된 구조로 개발하겠습니다 (data_collection, preprocessing, analysis, visualization 패키지 분리).
   - 테스트 코드를 함께 작성하는 TDD 방식을 적용하겠습니다.
   - CI/CD 파이프라인을 구축하여 코드 품질을 자동으로 관리하겠습니다.

4. **인프라:**
   - API 키는 처음부터 환경 변수로 관리하겠습니다.
   - 데이터 버전 관리를 위해 DVC(Data Version Control)를 도입하겠습니다.

5. **결과 활용:**
   - Streamlit 대시보드를 구축하여 비개발자도 쉽게 결과를 확인하고 탐색할 수 있도록 하겠습니다.

---

## 10. 심화 질문

### Q26. pandas에서 대용량 데이터를 처리할 때의 성능 최적화 방법은?

**모범답안:**

17,526건은 pandas로 충분히 처리 가능하지만, 데이터가 수백만 건으로 확장될 경우 다음 최적화 방법을 적용할 수 있습니다:

1. **데이터 타입 최적화:**
   ```python
   df['column'] = df['column'].astype('category')  # 반복 문자열 → 카테고리형
   df['int_col'] = df['int_col'].astype('int32')    # 64비트 → 32비트
   ```

2. **청크 단위 처리:**
   ```python
   for chunk in pd.read_csv('large_file.csv', chunksize=10000):
       process(chunk)
   ```

3. **벡터화 연산:** for 루프 대신 pandas/numpy의 벡터화 연산 사용

4. **인덱싱:** 자주 조회하는 컬럼에 인덱스 설정

5. **대안 라이브러리:**
   - Polars: Rust 기반으로 pandas 대비 5~10배 빠른 처리
   - Dask: 분산 처리로 메모리 초과 데이터 처리 가능
   - Vaex: 지연 평가(lazy evaluation)로 대용량 데이터 처리

---

### Q27. 이 프로젝트를 배포한다면 어떤 아키텍처를 구성하겠습니까?

**모범답안:**

프로덕션 환경을 고려한 아키텍처:

```
[데이터 수집 파이프라인]
  ├── Airflow/Prefect (스케줄러) → 주기적 크롤링 실행
  ├── Naver API / 웹 크롤러 → 리뷰 데이터 수집
  └── S3 / GCS → 원천 데이터 저장

[데이터 처리]
  ├── Spark / Pandas → 전처리 및 감성분석
  ├── MLflow → 모델 버전 관리
  └── PostgreSQL / BigQuery → 분석 결과 저장

[서빙 레이어]
  ├── FastAPI → REST API 제공
  ├── Streamlit / React → 대시보드 프론트엔드
  └── Docker + Kubernetes → 컨테이너 오케스트레이션

[모니터링]
  ├── Grafana → 시스템 모니터링
  └── 데이터 품질 체크 → Great Expectations
```

핵심 고려사항:
- 크롤링은 비동기(Celery + Redis)로 처리하여 효율성 확보
- 감성분석 모델은 모델 서버에서 API로 제공
- 결과 캐싱으로 반복 조회 성능 향상
- CI/CD 파이프라인으로 모델 업데이트 자동화

---

### Q28. 피어슨 상관계수와 스피어만 상관계수의 차이점은 무엇이고, 이 프로젝트에는 어떤 것이 더 적합했나요?

**모범답안:**

**피어슨 상관계수:**
- 두 변수 간의 **선형 관계**의 강도를 측정합니다.
- 전제: 두 변수가 정규분포를 따르고, 연속형 데이터여야 합니다.
- 범위: -1 ~ 1

**스피어만 상관계수:**
- 두 변수 간의 **단조(monotonic) 관계**를 측정합니다.
- 순위(rank) 기반으로 계산하므로 정규분포 가정이 불필요합니다.
- 이상치에 강건합니다.

**이 프로젝트에서의 적합성:**
- 감성 점수는 키워드 카운트 기반으로 엄밀한 연속 변수가 아니며, 정규분포를 따르지 않을 가능성이 높습니다.
- 시설 특성 변수도 이상치 캡핑 후에도 완전한 정규분포를 따르지 않습니다.
- 따라서 **스피어만 상관계수**가 더 적합했을 수 있습니다.
- 다만, 이 프로젝트에서는 이미 이상치를 캡핑하고 Min-Max Scaling을 적용했으므로 피어슨 상관계수도 합리적인 선택이었습니다.

---

### Q29. 만약 실시간으로 감성 분석을 해야 한다면 어떻게 설계하겠습니까?

**모범답안:**

실시간 감성 분석 파이프라인:

1. **데이터 스트리밍:**
   - Kafka나 Redis Streams로 새로운 리뷰 데이터를 실시간 수신
   - 웹훅이나 폴링으로 API에서 새 데이터 감지

2. **스트림 처리:**
   - Apache Flink나 Spark Streaming으로 실시간 전처리
   - 배치 + 스트리밍 하이브리드 아키텍처 (Lambda Architecture)

3. **모델 서빙:**
   - TorchServe나 TensorFlow Serving으로 ML 모델 API 제공
   - 모델 경량화(ONNX 변환, 양자화)로 응답 속도 최적화
   - 캐싱 레이어로 동일 텍스트 재처리 방지

4. **결과 저장 및 알림:**
   - 시계열 DB(InfluxDB)에 감성 점수 실시간 저장
   - 부정 리뷰 급증 시 Slack/이메일 알림 발송
   - Grafana 대시보드로 실시간 모니터링

5. **성능 목표:**
   - 지연시간(latency): 100ms 이내
   - 처리량(throughput): 1,000건/초 이상

---

### Q30. 이 프로젝트의 결과를 비개발자에게 어떻게 설명하겠습니까?

**모범답안:**

비개발자(도서관 운영자, 지자체 담당자)에게는 다음과 같이 설명하겠습니다:

"전국 3,500개 도서관에 대해 블로그에 작성된 리뷰 17,000건을 수집하고, 컴퓨터가 자동으로 각 리뷰가 긍정적인지 부정적인지를 판단하도록 했습니다.

**주요 발견:**
1. **시설 환경이 만족도에 가장 큰 영향**: 건물이 넓고 좌석이 많은 도서관일수록 이용자 만족도가 높은 경향이 있습니다.
2. **지역별 차이**: 각 지역마다 이용자들이 중요하게 생각하는 요소가 다릅니다. 워드클라우드를 통해 지역별 핵심 키워드를 한눈에 확인할 수 있습니다.
3. **시간에 따른 변화**: 연도별로 만족도가 어떻게 변하고 있는지, 특정 시기에 불만이 집중되는지 파악할 수 있습니다.

**활용 방안:**
- 만족도가 낮은 도서관에 우선적으로 개선 투자
- 부정 키워드 분석을 통해 구체적인 개선 항목 파악
- 우수 도서관의 성공 요인을 벤치마킹"

핵심은 기술적 세부사항보다 **인사이트와 활용 방안**에 초점을 맞추고, **시각화 자료**를 적극 활용하여 직관적으로 전달하는 것입니다.
